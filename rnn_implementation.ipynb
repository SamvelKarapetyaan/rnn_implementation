{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "with open(\"constitution.txt\", \"r\") as file:\n",
    "    txt = file.read()\n",
    "\n",
    "txt_arr = np.array(list(txt)).reshape(-1, 1)\n",
    "\n",
    "chars = np.array(['\\n', ' ', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3',\n",
    "        '4', '5', '6', '7', '8', '9', ':', ';', 'A', 'B', 'C', 'D', 'E',\n",
    "        'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',\n",
    "        'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
    "        'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't',\n",
    "        'u', 'v', 'w', 'x', 'y', 'z']).reshape(-1, 1)\n",
    "\n",
    "ohe.fit(chars)\n",
    "\n",
    "sentences = txt.split(\"\\n\")[:-1]\n",
    "\n",
    "batch_size = 5\n",
    "batches = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    encoded_sentence = ohe.transform(np.array(list(sentence)).reshape(-1, 1))\n",
    "    encoded_sentence = np.concatenate([encoded_sentence, np.zeros((1, len(ohe.categories_[0])))])\n",
    "\n",
    "    batches.append(encoded_sentence)\n",
    "\n",
    "# batches.sort(key=len) # Make batches\n",
    "len(ohe.categories_[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNN:\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_size, \n",
    "            hidden_size,\n",
    "            output_size,\n",
    "        ):\n",
    "        # self.train_mode = True \n",
    "        self.loss = \"cross_entropy\"\n",
    "        \n",
    "        self.input_weights = np.random.normal(loc = 0, scale = 2 / (input_size + output_size), size=(input_size, hidden_size))\n",
    "        self.hidden_weights = np.random.normal(loc = 0, scale = 1 / hidden_size, size=(hidden_size, hidden_size))\n",
    "        self.bias = np.zeros((1, hidden_size))\n",
    "\n",
    "        self.output_weights = np.random.normal(loc = 0, scale = 2 / (hidden_size + output_size), size=(hidden_size, output_size))\n",
    "        self.output_bias = np.zeros((1, output_size))\n",
    "        \n",
    "        self.hidden_state = np.zeros((1, hidden_size))\n",
    "        self.output = None\n",
    "\n",
    "        self._input_weights_gradient = np.zeros_like(self.input_weights) # Or init by 0\n",
    "        self._hidden_weights_gradient = np.zeros_like(self.hidden_weights)\n",
    "        self._output_weights_gradient = np.zeros_like(self.output_weights)\n",
    "\n",
    "        self._bias_gradient = 0\n",
    "        self._output_bias_gradient = 0\n",
    "\n",
    "        self._hidden_weights_gradient_recurrent = np.ones_like(self.hidden_weights)\n",
    "        self._input_weights_gradient_recurrent = np.ones_like(self.input_weights)\n",
    "        self._bias_gradient_recurrent = np.ones_like(self.bias)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        hidden_state = np.tanh(X @ self.input_weights + self.hidden_state @ self.hidden_weights + self.bias)\n",
    "        output = hidden_state @ self.output_weights + self.output_bias\n",
    "\n",
    "        return output, hidden_state\n",
    "\n",
    "    def loss_function(self, y_pred, y_true):\n",
    "\n",
    "        if self.loss == \"cross_entropy\":\n",
    "            # + softmax\n",
    "            self.probabilities_ = np.exp(y_pred) # - y_pred.max(axis=1, keepdims=True)) # avoid overflow\n",
    "            self.probabilities_ = self.probabilities_ / self.probabilities_.sum(axis=1, keepdims=True)\n",
    "\n",
    "            return -(np.log(self.probabilities_[np.arange(y_true.shape[0]), np.argmax(y_true, axis=1)])).mean()\n",
    "\n",
    "    def __loss_function_gradient(self, y_pred, y_true):\n",
    "\n",
    "        if self.loss == \"cross_entropy\":\n",
    "            return 1 / len(y_true) * (self.probabilities_ - y_true)\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        lr = 0.001\n",
    "\n",
    "        global_loss = 0\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            input_ = X[[i], :]\n",
    "            label_ = y[[i], :]\n",
    "\n",
    "            output_, hidden_state_ = self.forward(input_)\n",
    "\n",
    "            loss = self.loss_function(output_, label_) # May be wanna print\n",
    "            global_loss += loss\n",
    "\n",
    "            gradient = self.__loss_function_gradient(output_, label_)\n",
    "\n",
    "            self._output_weights_gradient += hidden_state_.T @ gradient\n",
    "            self._output_bias_gradient += gradient # (1, output)\n",
    "\n",
    "            recurrent_gradient = 1 - np.square(hidden_state_) # (1, hidden)\n",
    "\n",
    "            self._input_weights_gradient += (input_.T @ (1 - np.square(hidden_state_)) +  ((1 - np.square(hidden_state_) @ self.hidden_weights.T) * self._input_weights_gradient_recurrent)) * (gradient @ self.output_weights.T)\n",
    "\n",
    "            self._hidden_weights_gradient += (gradient @ self.output_weights.T) * (1 - np.square(hidden_state_)) * (self._hidden_weights_gradient_recurrent @ self.hidden_weights.T + self.hidden_state)\n",
    "\n",
    "            self._bias_gradient += (gradient @ self.output_weights.T) * (1 - np.square(hidden_state_)) @ (self._bias_gradient_recurrent + self.hidden_weights.T)\n",
    "\n",
    "\n",
    "\n",
    "            self._input_weights_gradient_recurrent *= ((1 - np.square(hidden_state_)) @ self.hidden_weights.T) * self._input_weights_gradient_recurrent # input, hidden\n",
    "            self._hidden_weights_gradient_recurrent *= (1 - np.square(hidden_state_)) * (self._hidden_weights_gradient_recurrent @ self.hidden_weights.T + self.hidden_state)\n",
    "            self._bias_gradient_recurrent *= (1 - np.square(hidden_state_)) @ (self._bias_gradient_recurrent + self.hidden_weights.T)\n",
    "                \n",
    "            self.hidden_state = hidden_state_\n",
    "        \n",
    "        self.input_weights -= lr * self._input_weights_gradient\n",
    "        self.output_weights -= lr * self._output_weights_gradient\n",
    "        self.output_bias -= lr * self._output_bias_gradient\n",
    "        self.hidden_weights -= lr * self._hidden_weights_gradient\n",
    "        self.bias -= lr * self._bias_gradient\n",
    "\n",
    "        print(global_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samvel\\AppData\\Local\\Temp\\ipykernel_12232\\2200655831.py:85: RuntimeWarning: overflow encountered in multiply\n",
      "  self._bias_gradient_recurrent *= (1 - np.square(hidden_state_)) @ (self._bias_gradient_recurrent + self.hidden_weights.T)\n",
      "C:\\Users\\Samvel\\AppData\\Local\\Temp\\ipykernel_12232\\2200655831.py:79: RuntimeWarning: invalid value encountered in matmul\n",
      "  self._bias_gradient += (gradient @ self.output_weights.T) * (1 - np.square(hidden_state_)) @ (self._bias_gradient_recurrent + self.hidden_weights.T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402.5503151511314\n"
     ]
    }
   ],
   "source": [
    "rnn = VanillaRNN(72, 142, 72)\n",
    "X = batches[0]\n",
    "rnn.fit(X, X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
